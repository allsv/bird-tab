{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068539cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Auto-install minimal deps if missing\n",
    "def ensure(pkg):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "for _p in [\"requests\", \"pandas\", \"ipywidgets\", \"tqdm\", \"beautifulsoup4\"]:\n",
    "    ensure(_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as w\n",
    "from IPython.display import display\n",
    "display(w.Button(description=\"Widgets OK\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c24e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, IFrame\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"tab\" / \"app.js\").exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"Could not locate tab/app.js from {start}\")\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "APP_JS = REPO_ROOT / \"tab\" / \"app.js\"\n",
    "app_js = APP_JS.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "# Extract the iframeLinks array block\n",
    "m = re.search(r\"const\\s+iframeLinks\\s*=\\s*\\[(.*?)\\];\", app_js, re.S)\n",
    "block = m.group(1) if m else app_js  # fallback: scan whole file\n",
    "\n",
    "# Extract all quoted URLs inside the block\n",
    "urls = re.findall(r'\"(https?://[^\"\\s]+)\"', block)\n",
    "urls = [u.strip() for u in urls]\n",
    "\n",
    "if not urls:\n",
    "    raise RuntimeError(\"No URLs found. Check APP_JS path or the iframeLinks declaration.\")\n",
    "\n",
    "# Build dataframe\n",
    "def extract_asset_id(u: str):\n",
    "    mm = re.search(r\"/asset/(\\d+)\", u)\n",
    "    return mm.group(1) if mm else None\n",
    "\n",
    "def ends_with_embed(u: str):\n",
    "    return u.rstrip(\"/\").endswith(\"embed\")\n",
    "\n",
    "rows = []\n",
    "seen = {}\n",
    "for idx, u in enumerate(urls):\n",
    "    dom = urlparse(u).netloc\n",
    "    aid = extract_asset_id(u)\n",
    "    rows.append(\n",
    "        dict(\n",
    "            index=idx,\n",
    "            url=u,\n",
    "            domain=dom,\n",
    "            asset_id=aid,\n",
    "            ends_with_embed=ends_with_embed(u),\n",
    "        )\n",
    "    )\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Mark duplicates (same exact URL)\n",
    "df[\"duplicate\"] = df[\"url\"].duplicated(keep=\"first\")\n",
    "\n",
    "# Simple suspicious flags\n",
    "df[\"missing_asset_id\"] = df[\"asset_id\"].isna()\n",
    "df[\"non_numeric_asset\"] = False  # asset_id regex guarantees numeric if present\n",
    "df[\"suspicious\"] = df[[\"duplicate\", \"missing_asset_id\"]].any(axis=1) | (~df[\"ends_with_embed\"])\n",
    "\n",
    "display(df.head(10))\n",
    "print(f\"Total URLs: {len(df)} | Duplicates: {df['duplicate'].sum()} | Suspicious: {df['suspicious'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.auto import tqdm\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "MAX_WORKERS = 30      # was 10\n",
    "TIMEOUT = 5           # was 10\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"LinkAudit/1.0 (+https://github.com/your-repo)\",\n",
    "    \"Accept\": \"*/*\",\n",
    "}\n",
    "\n",
    "# Reusable session with retries for transient errors\n",
    "session = requests.Session()\n",
    "retries = Retry(total=2, backoff_factor=0.2, status_forcelist=[429, 500, 502, 503, 504])\n",
    "session.mount(\"http://\", HTTPAdapter(max_retries=retries))\n",
    "session.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "\n",
    "def _extract_sci_from_desc(desc: str) -> str | None:\n",
    "    # description example: \"Macaulay Library ML92547181; Rock Pigeon (Feral Pigeon); Columba livia (Feral Pigeon)\"\n",
    "    parts = [p.strip() for p in desc.split(\";\") if p.strip()]\n",
    "    if not parts:\n",
    "        return None\n",
    "    sci = parts[-1]\n",
    "    # keep only the binomial \"Genus species\"\n",
    "    sci = re.sub(r\"\\s*\\(.*?\\)\\s*$\", \"\", sci).strip()\n",
    "    m = re.search(r\"\\b([A-Z][a-z]+)\\s+([a-z]+)\\b\", sci)\n",
    "    return f\"{m.group(1)} {m.group(2)}\" if m else None\n",
    "\n",
    "def parse_species_name_from_html(html: str) -> str | None:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # 1) Prefer the rendered species block in the embed\n",
    "    #    <div class=\"speciesName\"> ... <span class=\"Species-sci ...\">Columba livia (Feral Pigeon)</span>\n",
    "    container = soup.select_one(\"div.speciesName\")\n",
    "    if container:\n",
    "        txt = container.get_text(\" \", strip=True)\n",
    "        m = re.search(r\"\\b([A-Z][a-z]+)\\s+([a-z]+)\\b\", re.sub(r\"\\s*\\(.*?\\)\\s*\", \" \", txt))\n",
    "        if m:\n",
    "            return f\"{m.group(1)} {m.group(2)}\"\n",
    "\n",
    "    sci_el = soup.select_one(\".Species-sci\")\n",
    "    if sci_el:\n",
    "        txt = sci_el.get_text(\" \", strip=True)\n",
    "        txt = re.sub(r\"\\s*\\(.*?\\)\\s*$\", \"\", txt).strip()\n",
    "        m = re.search(r\"\\b([A-Z][a-z]+)\\s+([a-z]+)\\b\", txt)\n",
    "        if m:\n",
    "            return f\"{m.group(1)} {m.group(2)}\"\n",
    "\n",
    "    # 2) Fallback to meta description content if present (then normalize)\n",
    "    meta = soup.find(\"meta\", attrs={\"name\": \"description\"}) or soup.find(\"meta\", attrs={\"property\": \"og:description\"})\n",
    "    if meta and meta.get(\"content\"):\n",
    "        sci = _extract_sci_from_desc(meta[\"content\"])\n",
    "        if sci:\n",
    "            return sci\n",
    "\n",
    "    return None\n",
    "\n",
    "def check_one(u: str):\n",
    "    t0 = time.time()\n",
    "    err = None\n",
    "    code = None\n",
    "    final_url = None\n",
    "    method = \"HEAD\"\n",
    "    ok = False\n",
    "    species_name = None  # NEW\n",
    "    try:\n",
    "        r = session.head(u, allow_redirects=True, timeout=TIMEOUT, headers=headers)\n",
    "        code = r.status_code\n",
    "        final_url = r.url\n",
    "        if code in (405, 403, 400):\n",
    "            method = \"GET\"\n",
    "            r2 = session.get(u, allow_redirects=True, timeout=TIMEOUT, headers=headers, stream=True)\n",
    "            code = r2.status_code\n",
    "            final_url = r2.url\n",
    "            r2.close()\n",
    "        ok = 200 <= code < 400\n",
    "\n",
    "        # If it's a Macaulay Library embed, GET the HTML and extract the sci name\n",
    "        if ok:\n",
    "            host = urlparse(final_url or u).netloc.lower()\n",
    "            if \"macaulaylibrary.org\" in host:\n",
    "                r3 = session.get(final_url or u, allow_redirects=True, timeout=TIMEOUT, headers=headers)\n",
    "                species_name = parse_species_name_from_html(r3.text)\n",
    "    except requests.RequestException as e:\n",
    "        err = str(e)\n",
    "    dt = time.time() - t0\n",
    "    return dict(\n",
    "        status_code=code,\n",
    "        ok=ok,\n",
    "        error=err,\n",
    "        final_url=final_url,\n",
    "        method=method,\n",
    "        elapsed_s=round(dt, 3),\n",
    "        species_name=species_name,  # NEW\n",
    "    )\n",
    "\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    futs = {ex.submit(check_one, u): i for i, u in enumerate(df[\"url\"])}\n",
    "    for fut in tqdm(as_completed(futs), total=len(futs), desc=\"Checking links\"):\n",
    "        i = futs[fut]\n",
    "        res = fut.result()\n",
    "        results.append((i, res))\n",
    "\n",
    "# Merge results back\n",
    "res_map = {i: r for i, r in results}\n",
    "df[\"status_code\"] = df[\"index\"].map(lambda i: res_map.get(i, {}).get(\"status_code\"))\n",
    "df[\"ok\"] = df[\"index\"].map(lambda i: res_map.get(i, {}).get(\"ok\", False))\n",
    "df[\"error\"] = df[\"index\"].map(lambda i: res_map.get(i, {}).get(\"error\"))\n",
    "df[\"final_url\"] = df[\"index\"].map(lambda i: res_map.get(i, {}).get(\"final_url\"))\n",
    "df[\"method_used\"] = df[\"index\"].map(lambda i: res_map.get(i, {}).get(\"method\"))\n",
    "df[\"elapsed_s\"] = df[\"index\"].map(lambda i: res_map.get(i, {}).get(\"elapsed_s\"))\n",
    "df[\"species_name\"] = df[\"index\"].map(lambda i: res_map.get(i, {}).get(\"species_name\"))\n",
    "\n",
    "df_sorted = df.sort_values(by=[\"ok\", \"suspicious\", \"status_code\"], ascending=[True, False, True])\n",
    "display(df_sorted.head(20))\n",
    "print(f\"OK: {df['ok'].sum()} | Broken: {(~df['ok']).sum()} | With errors: {df['error'].notna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMBIDAE_GENERA = {\n",
    "    \"Alectroenas\",\"Alopecoenas\",\"Pampusana\",\"Caloenas\",\"Chalcophaps\",\"Claravis\",\"Paraclaravis\",\n",
    "    \"Columbina\",\"Columba\",\"Didunculus\",\"Drepanoptila\",\"Ducula\",\"Ectopistes\",\"Gallicolumba\", \"Geophaps\",\"Geopelia\",\n",
    "    \"Geotrygon\",\"Zentrygon\",\"Goura\",\"Gymnophaps\",\"Hemiphaga\",\"Henicophaps\",\"Leptotila\",\"Leucosarcia\",\n",
    "    \"Lopholaimus\",\"Macropygia\",\"Metriopelia\",\"Microgoura\",\"Nesoenas\",\"Ocyphaps\",\"Oena\",\"Otidiphaps\",\n",
    "    \"Patagioenas\",\"Pezophaps\",\"Phapitreron\",\"Phaps\",\"Ptilinopus\",\"Reinwardtoena\",\"Raphus\",\"Spilopelia\",\n",
    "    \"Streptopelia\",\"Starnoenas\",\"Treron\",\"Trugon\",\"Turtur\",\"Uropelia\",\"Zenaida\",\"Petrophassa\"\n",
    "}\n",
    "\n",
    "# first token of species_name is the genus\n",
    "df[\"genus\"] = df[\"species_name\"].str.extract(r\"^([A-Z][a-z]+)\\b\")\n",
    "df[\"is_columbidae_genus\"] = df[\"genus\"].isin(COLUMBIDAE_GENERA)\n",
    "df[\"family\"] = df[\"is_columbidae_genus\"].map({True: \"Columbidae\", False: None})\n",
    "df[\"family_mismatch\"] = df[\"species_name\"].notna() & ~df[\"is_columbidae_genus\"]\n",
    "\n",
    "df_sorted = df.sort_values(by=[\"ok\", \"suspicious\", \"status_code\"], ascending=[True, False, True])\n",
    "display(df_sorted.head(20))\n",
    "print(f\"OK: {df['ok'].sum()} | Broken: {(~df['ok']).sum()} | With errors: {df['error'].notna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfe39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_CSV = Path(APP_JS).parent.parent / \"link_audit.csv\"\n",
    "df_sorted.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Saved: {OUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb3d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = df.index.tolist()\n",
    "\n",
    "def subset_indices(mode: str):\n",
    "    if (\"ok\" in df.columns) and mode == \"broken\":\n",
    "        return df.index[~df[\"ok\"]].tolist()\n",
    "    if mode == \"suspicious\":\n",
    "        return df.index[df[\"suspicious\"]].tolist()\n",
    "    if mode == \"duplicates\":\n",
    "        return df.index[df[\"duplicate\"]].tolist()\n",
    "    return all_indices\n",
    "\n",
    "mode = widgets.ToggleButtons(options=[\"all\", \"broken\", \"suspicious\", \"duplicates\"], description=\"View:\")\n",
    "show_iframe = widgets.Checkbox(value=True, description=\"Preview iframe\")\n",
    "i_slider = widgets.IntSlider(value=0, min=0, max=max(0, len(all_indices)-1), description=\"Index\")\n",
    "prev_btn = widgets.Button(description=\"Prev\")\n",
    "next_btn = widgets.Button(description=\"Next\")\n",
    "\n",
    "out = widgets.Output()\n",
    "state = {\"indices\": subset_indices(\"all\")}\n",
    "\n",
    "def sync_slider_range():\n",
    "    i_slider.max = max(0, len(state[\"indices\"]) - 1)\n",
    "    i_slider.value = min(i_slider.value, i_slider.max)\n",
    "\n",
    "def render():\n",
    "    out.clear_output()\n",
    "    if not state[\"indices\"]:\n",
    "        with out:\n",
    "            display(HTML(\"<b>No items in this view.</b>\"))\n",
    "        return\n",
    "    idx = state[\"indices\"][i_slider.value]\n",
    "    row = df.loc[idx]\n",
    "    meta = []\n",
    "    meta.append(f\"Index in list: {row['index']}\")\n",
    "    if \"ok\" in df.columns:\n",
    "        meta.append(f\"Status: {'OK' if row['ok'] else 'BROKEN'} ({row['status_code']})\")\n",
    "        if pd.notna(row.get(\"error\")):\n",
    "            meta.append(f\"Error: {row['error']}\")\n",
    "    meta.append(f\"Duplicate: {row['duplicate']}\")\n",
    "    meta.append(f\"Ends with /embed: {row['ends_with_embed']}\")\n",
    "    meta.append(f\"Asset ID: {row['asset_id'] or '(none)'}\")\n",
    "    meta.append(f\"Domain: {row['domain']}\")\n",
    "    html = f\"\"\"\n",
    "    <div style='font-family: sans-serif'>\n",
    "        <div style='margin-bottom:8px'>\n",
    "            <a href=\"{row['url']}\" target=\"_blank\">{row['url']}</a>\n",
    "        </div>\n",
    "        <div style='color:#444; margin-bottom:8px'>{' | '.join(meta)}</div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    with out:\n",
    "        display(HTML(html))\n",
    "        if show_iframe.value:\n",
    "            try:\n",
    "                iframe_html = f\"\"\"\n",
    "                <iframe\n",
    "                    src=\"{row['url']}\"\n",
    "                    width=\"900\"\n",
    "                    height=\"540\"\n",
    "                    style=\"border:0\"\n",
    "                    loading=\"lazy\"\n",
    "                    allow=\"autoplay; fullscreen; clipboard-write\"\n",
    "                    sandbox=\"allow-scripts allow-same-origin allow-popups allow-forms\">\n",
    "                </iframe>\n",
    "                \"\"\"\n",
    "                display(HTML(iframe_html))\n",
    "            except Exception as e:\n",
    "                display(HTML(f\"<i>Preview failed: {e}</i>\"))\n",
    "\n",
    "def on_mode_change(change):\n",
    "    state[\"indices\"] = subset_indices(change[\"new\"])\n",
    "    sync_slider_range()\n",
    "    render()\n",
    "\n",
    "def on_prev(_):\n",
    "    if i_slider.value > 0:\n",
    "        i_slider.value -= 1\n",
    "\n",
    "def on_next(_):\n",
    "    if i_slider.value < i_slider.max:\n",
    "        i_slider.value += 1\n",
    "\n",
    "mode.observe(on_mode_change, names=\"value\")\n",
    "show_iframe.observe(lambda ch: render(), names=\"value\")\n",
    "prev_btn.on_click(on_prev)\n",
    "next_btn.on_click(on_next)\n",
    "i_slider.observe(lambda ch: render(), names=\"value\")\n",
    "\n",
    "controls = widgets.HBox([mode, show_iframe, prev_btn, next_btn, i_slider])\n",
    "display(controls, out)\n",
    "\n",
    "render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "broken = df[~df['ok']] if 'ok' in df.columns else pd.DataFrame()\n",
    "family_mismatch = df[df['family_mismatch']] if 'family_mismatch' in df.columns else pd.DataFrame()\n",
    "suspicious = df[df['suspicious'] & ~df.get('family_mismatch', False)]  # suspicious but not family issues\n",
    "duplicates = df[df['duplicate']]\n",
    "ok_links = df[df['ok'] & ~df.get('family_mismatch', False)] if 'ok' in df.columns else df\n",
    "\n",
    "def make_card(row, show_status=True):\n",
    "    status_class = \"broken\" if not row.get('ok', True) else (\"mismatch\" if row.get('family_mismatch', False) else \"ok\")\n",
    "    status_parts = []\n",
    "    if show_status and 'ok' in df.columns:\n",
    "        status_parts.append(f\"Status: {'OK' if row.get('ok', False) else 'BROKEN'} ({row.get('status_code', '')})\")\n",
    "    if pd.notna(row.get('species_name')):\n",
    "        status_parts.append(f\"Species: {row['species_name']}\")\n",
    "    if pd.notna(row.get('family')):\n",
    "        status_parts.append(f\"Family: {row['family']}\")\n",
    "    status_text = ' | '.join(status_parts)\n",
    "    \n",
    "    return f\"\"\"\n",
    "    <div class=\"card {status_class}\" data-index=\"{row['index']}\" data-status=\"{status_class}\">\n",
    "      <div class=\"meta\">\n",
    "        <span class=\"index\">#{row['index']}</span>\n",
    "        <a href=\"{row['url']}\" target=\"_blank\" class=\"url\">{row['url']}</a>\n",
    "        <span class=\"info\">Asset: {row['asset_id'] or 'none'} | Dup: {row['duplicate']} | {status_text}</span>\n",
    "      </div>\n",
    "      <iframe src=\"{row['url']}\" width=\"100%\" height=\"540\" style=\"border:0\"\n",
    "              allow=\"autoplay; fullscreen; clipboard-write\" loading=\"lazy\" allowfullscreen></iframe>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "sections = []\n",
    "if len(broken) > 0:\n",
    "    sections.append(f\"<h2 id='broken'>‚ùå Broken ({len(broken)})</h2>\")\n",
    "    sections.append('<div class=\"section\">'+'\\n'.join(make_card(r) for _, r in broken.iterrows())+'</div>')\n",
    "\n",
    "if len(family_mismatch) > 0:\n",
    "    sections.append(f\"<h2 id='mismatch'>üö´ Not Columbidae ({len(family_mismatch)})</h2>\")\n",
    "    sections.append('<div class=\"section\">'+'\\n'.join(make_card(r) for _, r in family_mismatch.iterrows())+'</div>')\n",
    "\n",
    "if len(suspicious) > 0:\n",
    "    sections.append(f\"<h2 id='suspicious'>‚ö†Ô∏è Suspicious ({len(suspicious)})</h2>\")\n",
    "    sections.append('<div class=\"section\">'+'\\n'.join(make_card(r) for _, r in suspicious.iterrows())+'</div>')\n",
    "\n",
    "if len(duplicates) > 0:\n",
    "    sections.append(f\"<h2 id='duplicates'>üîÅ Duplicates ({len(duplicates)})</h2>\")\n",
    "    sections.append('<div class=\"section\">'+'\\n'.join(make_card(r, False) for _, r in duplicates.iterrows())+'</div>')\n",
    "\n",
    "sections.append(f\"<h2 id='all'>‚úÖ All OK ({len(ok_links)})</h2>\")\n",
    "sections.append('<div class=\"section collapsed\">'+'\\n'.join(make_card(r) for _, r in ok_links.iterrows())+'</div>')\n",
    "\n",
    "html = f\"\"\"<!doctype html>\n",
    "<html><head><meta charset=\"utf-8\"><title>Link Audit - {len(df)} links</title>\n",
    "<style>\n",
    "body {{ font-family: Arial, sans-serif; margin: 16px; background: #f5f5f5; }}\n",
    "h2 {{ margin: 24px 0 12px; cursor: pointer; user-select: none; }}\n",
    "h2:hover {{ text-decoration: underline; }}\n",
    ".section {{ margin-bottom: 24px; }}\n",
    ".section.collapsed .card {{ display: none; }}\n",
    ".card {{ background: white; margin: 12px 0; padding: 12px; border: 1px solid #ddd; border-radius: 4px; }}\n",
    ".card.broken {{ border-left: 4px solid #e74c3c; }}\n",
    ".card.mismatch {{ border-left: 4px solid #f39c12; }}\n",
    ".card.ok {{ border-left: 4px solid #2ecc71; }}\n",
    ".meta {{ margin-bottom: 8px; font-size: 14px; }}\n",
    ".index {{ font-weight: bold; color: #666; margin-right: 8px; }}\n",
    ".url {{ color: #3498db; text-decoration: none; margin-right: 8px; }}\n",
    ".url:hover {{ text-decoration: underline; }}\n",
    ".info {{ color: #999; font-size: 13px; }}\n",
    ".controls {{ position: sticky; top: 0; background: white; padding: 12px; border: 1px solid #ddd; \n",
    "             margin-bottom: 16px; z-index: 100; display: flex; gap: 12px; align-items: center; }}\n",
    "button {{ padding: 8px 16px; cursor: pointer; border: 1px solid #ccc; background: white; border-radius: 4px; }}\n",
    "button:hover {{ background: #f0f0f0; }}\n",
    "input {{ padding: 8px; border: 1px solid #ccc; border-radius: 4px; flex: 1; max-width: 300px; }}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<div class=\"controls\">\n",
    "  <input type=\"text\" id=\"search\" placeholder=\"Search URLs, species, or asset IDs...\">\n",
    "  <button onclick=\"toggleAll()\">Expand/Collapse All</button>\n",
    "  <span>Total: {len(df)} | Broken: {len(broken)} | Non-Columbidae: {len(family_mismatch)} | Suspicious: {len(suspicious)}</span>\n",
    "</div>\n",
    "{''.join(sections)}\n",
    "<script>\n",
    "const search = document.getElementById('search');\n",
    "search.addEventListener('input', e => {{\n",
    "  const q = e.target.value.toLowerCase();\n",
    "  document.querySelectorAll('.card').forEach(c => {{\n",
    "    const text = c.textContent.toLowerCase();\n",
    "    c.style.display = text.includes(q) ? 'block' : 'none';\n",
    "  }});\n",
    "}});\n",
    "\n",
    "document.querySelectorAll('h2').forEach(h => {{\n",
    "  h.addEventListener('click', () => {{\n",
    "    h.nextElementSibling.classList.toggle('collapsed');\n",
    "  }});\n",
    "}});\n",
    "\n",
    "function toggleAll() {{\n",
    "  document.querySelectorAll('.section').forEach(s => s.classList.toggle('collapsed'));\n",
    "}}\n",
    "</script>\n",
    "</body></html>\"\"\"\n",
    "\n",
    "out_file = Path.cwd() / \"_link_audit_categorized.html\"\n",
    "out_file.write_text(html, encoding=\"utf-8\")\n",
    "webbrowser.open(out_file.as_uri())\n",
    "print(f\"Categorized gallery: {out_file}\")\n",
    "print(f\"Broken: {len(broken)} | Non-Columbidae: {len(family_mismatch)} | Suspicious: {len(suspicious)} | Duplicates: {len(duplicates)} | OK: {len(ok_links)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
